# -*- coding: utf-8 -*-
"""Stablecoin Monitor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lLWHLuy5sTp_4fUyZT7cA3DdmHBdpHzZ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.ensemble import IsolationForest
from datetime import datetime, timedelta
import requests
import time

# --- Page Configuration ---
st.set_page_config(
    page_title="Stablecoin Risk Monitor",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS for Professional Look ---
st.markdown("""
<style>
    .metric-card {
        background-color: #0e1117;
        border: 1px solid #30333d;
        border-radius: 5px;
        padding: 15px;
        text-align: center;
    }
    .risk-high { color: #ff4b4b; font-weight: bold; }
    .risk-med { color: #ffa421; font-weight: bold; }
    .risk-low { color: #21c354; font-weight: bold; }
    .history-card {
        background-color: #ffffff;
        border: 1px solid #41444e;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- Constants: Historical Depeg Events ---
DEPEG_EVENTS = [
    {
        "date": "2023-03-11",
        "event": "Silicon Valley Bank Collapse",
        "price_impact": "USDC $0.870",
        "panic_score": 5,
        "panic_icon": "üè¶",
        "vibe": "My money is stuck in a bank?",
        "description": "Circle (USDC) revealed $3.3B was stuck in failed SVB. USDC crashed to 87 cents.",
        "link": "https://www.coindesk.com/markets/2023/03/11/usdc-stablecoin-depegs-falls-to-087-amid-svb-panic/"
    },
    {
        "date": "2023-08-07",
        "event": "Curve 3Pool Imbalance",
        "price_impact": "USDT $0.997",
        "panic_score": 2,
        "panic_icon": "üê≥",
        "vibe": "Whales playing games.",
        "description": "Heavy selling in DeFi's main pool (Curve) caused a wobble. Arbitrage bots fixed it quickly.",
        "link": "https://www.coindesk.com/markets/2023/08/07/tether-cto-says-usdt-redemptions-proceeding-normally-amid-curve-3pool-imbalance/"
    },
    {
        "date": "2022-11-10",
        "event": "FTX Collapse Contagion",
        "price_impact": "USDT $0.970",
        "panic_score": 4,
        "panic_icon": "üìâ",
        "vibe": "Is anything real anymore?",
        "description": "FTX imploded. Massive fear of contagion across all stablecoins.",
        "link": "https://www.cnbc.com/2022/11/10/tether-usdt-stablecoin-falls-below-1-dollar-peg-amid-crypto-market-panic.html"
    },
    {
        "date": "2022-05-12",
        "event": "Terra (LUNA) Collapse",
        "price_impact": "UST $0.000",
        "panic_score": 5,
        "panic_icon": "üíÄ",
        "vibe": "The day crypto stood still.",
        "description": "Algorithmic stablecoin UST went to zero. Trust in ALL stablecoins evaporated overnight.",
        "link": "https://www.bloomberg.com/news/articles/2022-05-12/tether-drops-below-1-in-startling-sign-of-crypto-market-strain"
    }
]

# --- Helper Functions ---

# 1. CRYPTOCOMPARE API FUNCTION
@st.cache_data(ttl=3600)  # Cache for 1 hour to prevent API spam
def fetch_crypto_data(coin='USDT', days=90):
    """
    Fetch REAL hourly data for selected coin from CryptoCompare API.
    No simulation. No fake data. Pure API calls.
    """
    base_url = "https://min-api.cryptocompare.com/data/v2/histohour"
    all_data = []

    # We want data ending NOW
    current_time = int(datetime.now().timestamp())
    hours_needed = days * 24

    # API Limitation: 2000 points per call
    limit = 2000
    num_requests = (hours_needed // limit) + 1

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        for batch in range(num_requests):
            status_text.text(f"Fetching {coin} data batch {batch+1}/{num_requests} from CryptoCompare...")

            params = {
                'fsym': coin,
                'tsym': 'USD',
                'limit': min(limit, hours_needed - len(all_data)),
                'toTs': current_time
            }

            response = requests.get(base_url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            if data['Response'] == 'Success':
                batch_data = data['Data']['Data']

                # Prepend new batch to existing data (API gives oldest-to-newest relative to toTs)
                # But since we walk backwards in time (updating toTs), we add to list
                all_data = batch_data + all_data

                if batch_data:
                    # Update 'toTs' to the oldest timestamp in this batch for the next loop
                    current_time = batch_data[0]['time']

                progress_bar.progress((batch + 1) / num_requests)
            else:
                st.error(f"API Error: {data.get('Message', 'Unknown error')}")
                break

            # Politeness delay
            time.sleep(0.2)

        status_text.empty()
        progress_bar.empty()

        if not all_data:
            return None

        # Convert to DataFrame
        df = pd.DataFrame(all_data)
        df['Datetime'] = pd.to_datetime(df['time'], unit='s')
        df['Close'] = df['close']

        # Sort and Filter
        df = df[['Datetime', 'Close']].sort_values('Datetime')
        cutoff_date = datetime.now() - timedelta(days=days)
        df = df[df['Datetime'] >= cutoff_date]

        return df

    except Exception as e:
        st.error(f"Connection Error: {e}")
        return None

# 2. ML ENGINE
def calculate_metrics(df, contamination=0.01):
    data = df.copy()

    # Feature Engineering
    data['Returns'] = data['Close'].pct_change()
    data['Volatility_24h'] = data['Returns'].rolling(window=24).std() * 100
    data['Deviation'] = (data['Close'] - 1.0)
    data = data.dropna()

    # Isolation Forest
    features = ['Close', 'Volatility_24h']
    model = IsolationForest(contamination=contamination, random_state=42)
    data['Anomaly'] = model.fit_predict(data[features])
    data['Is_Anomaly'] = data['Anomaly'] == -1

    # Rolling 7-day Volatility for bottom chart
    data['Volatility_7d'] = data['Returns'].rolling(window=24*7).std() * 100

    return data

# --- Sidebar ---
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")

    # Coin Selector
    selected_coin = st.selectbox("Select Stablecoin", ["USDT", "USDC"])

    st.caption(f"Fetching real hourly data for {selected_coin} via CryptoCompare.")
    days_to_fetch = st.slider("Days to Analyze", 7, 365, 90)

    if st.button("üîÑ Force Refresh Data"):
        st.cache_data.clear()
        st.rerun()

    st.divider()
    st.subheader("Anomaly Detection")
    contamination = st.slider("Sensitivity", 0.001, 0.05, 0.01, format="%.3f")
    st.info("**Stack:** Python, Streamlit, Plotly, Sklearn, CryptoCompare API")

# --- Main Content ---
st.title(f"üõ°Ô∏è {selected_coin} Stability Risk Monitor")

# 1. Load Data
raw_df = fetch_crypto_data(coin=selected_coin, days=days_to_fetch)

# 2. Process & Visualize
if raw_df is not None:
    st.toast(f"Data Up-to-Date: {len(raw_df)} hours loaded", icon="‚úÖ")

    processed_df = calculate_metrics(raw_df, contamination)

    # Get Latest Metrics
    latest = processed_df.iloc[-1]
    last_price = latest['Close']
    deviation_pct = (last_price - 1.0) * 100

    # Risk Logic
    # Low: 0.999-1.001 (Deviation < 0.1%)
    # Elevated: Deviation > 0.1%
    # Critical: Deviation > 0.5% OR Anomaly

    risk_score = "LOW"
    risk_color = "risk-low"

    if abs(deviation_pct) > 0.5 or latest['Is_Anomaly']:
        risk_score = "CRITICAL"
        risk_color = "risk-high"
    elif abs(deviation_pct) > 0.1:
        risk_score = "ELEVATED"
        risk_color = "risk-med"

    # Top Cards
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("Current Price", f"${last_price:.4f}", f"{deviation_pct:.3f}% (Peg)")
    with col2: st.metric("24h Volatility", f"{latest['Volatility_24h']:.4f}%")
    with col3: st.metric("Anomalies (Period)", f"{processed_df['Is_Anomaly'].sum()}")
    with col4: st.markdown(f"<div class='metric-card'><span style='color:#888'>Risk Level</span><br><span class='{risk_color}' style='font-size:1.5em'>{risk_score}</span></div>", unsafe_allow_html=True)

    # Tabs
    tab1, tab2, tab3 = st.tabs(["üìä Interactive Dashboard", "üçø Hall of Panic", "üìã Raw Data"])

    with tab1:
        fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05,
                            subplot_titles=(f"{selected_coin} Price vs Peg", "Deviation (%)", "7-Day Volatility"),
                            row_heights=[0.5, 0.25, 0.25])

        # Row 1: Price
        fig.add_trace(go.Scatter(x=processed_df['Datetime'], y=processed_df['Close'], mode='lines', name='Price', line=dict(color='#1f77b4', width=1.5)), row=1, col=1)
        fig.add_hline(y=1.0, line_dash="dash", line_color="gray", row=1, col=1)

        # Anomalies
        anom = processed_df[processed_df['Is_Anomaly']]
        fig.add_trace(go.Scatter(x=anom['Datetime'], y=anom['Close'], mode='markers', name='ML Anomaly', marker=dict(color='red', size=6, symbol='x')), row=1, col=1)

        # Row 2: Deviation
        fig.add_trace(go.Scatter(x=processed_df['Datetime'], y=processed_df['Close']-1, mode='lines', name='Deviation', fill='tozeroy', line=dict(color='#ff7f0e')), row=2, col=1)

        # Row 3: Volatility
        fig.add_trace(go.Scatter(x=processed_df['Datetime'], y=processed_df['Volatility_7d'], mode='lines', name='Vol (7d)', line=dict(color='#9467bd')), row=3, col=1)

        fig.update_layout(height=700, template="plotly_dark", showlegend=False, margin=dict(l=20, r=20, t=40, b=20))
        st.plotly_chart(fig, use_container_width=True)
        st.caption("Disclaimer: Anomaly detection is based on unsupervised machine learning (Isolation Forest) and is for educational monitoring only.")

    with tab2:
        st.markdown("### üé¢ The History of Volatility")
        st.markdown("A look back at historical moments when 'Stable' coins weren't so stable.")
        for event in DEPEG_EVENTS:
            border_color = "#ff4b4b" if event['panic_score'] >= 4 else "#ffa421" if event['panic_score'] >= 3 else "#21c354"
            st.markdown(f"""
            <div class="history-card" style="border-left: 5px solid {border_color}">
                <h4>{event['panic_icon']} {event['event']} <span style="font-size:0.8em; color:#888; float:right">{event['date']}</span></h4>
                <p><i>"{event['vibe']}"</i></p>
                <p>{event['description']}</p>
                <hr style="margin: 5px 0; border-color: #444;">
                <div style="display: flex; justify-content: space-between; font-size: 0.9em;">
                    <span><b>Panic Meter:</b> {'üî•' * event['panic_score']} ({event['panic_score']}/5)</span>
                    <span><b>Impact:</b> {event['price_impact']}</span>
                    <a href="{event['link']}" target="_blank" style="text-decoration:none;">Read More ‚Üó</a>
                </div>
            </div>
            """, unsafe_allow_html=True)

    with tab3:
        st.dataframe(processed_df, use_container_width=True)
        st.download_button(f"Download {selected_coin} CSV", processed_df.to_csv(index=False).encode('utf-8'), f"{selected_coin.lower()}_data.csv", "text/csv")
else:
    st.error("Failed to fetch data. Please check your internet connection or try again later.")
